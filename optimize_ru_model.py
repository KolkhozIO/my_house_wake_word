#!/usr/bin/env python3
"""
–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä—É—Å—Å–∫–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
"""

import tensorflow as tf
import numpy as np
import os

def optimize_ru_model():
    """–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ä—É—Å—Å–∫—É—é –º–æ–¥–µ–ª—å"""
    
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ - –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(40, 49)),
        tf.keras.layers.Reshape((40, 49, 1)),
        
        # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫ - –º–µ–Ω—å—à–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Dropout(0.25),
        
        # –í—Ç–æ—Ä–æ–π –±–ª–æ–∫ - –º–µ–Ω—å—à–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Dropout(0.25),
        
        # –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫ - –º–µ–Ω—å—à–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        tf.keras.layers.Conv2D(48, (3, 3), activation='relu'),
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dropout(0.5),
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏ - –º–µ–Ω—å—à–µ –Ω–µ–π—Ä–æ–Ω–æ–≤
        tf.keras.layers.Dense(48, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(24, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–º–ø–∏–ª—è—Ü–∏–∏
    dummy_data = np.random.random((100, 40, 49))
    dummy_labels = np.random.randint(0, 2, (100, 1))
    
    # –û–±—É—á–∞–µ–º –Ω–∞ —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (5 —ç–ø–æ—Ö)
    model.fit(dummy_data, dummy_labels, epochs=5, verbose=0)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model_dir = "models/trained_model"
    os.makedirs(model_dir, exist_ok=True)
    
    # H5 –º–æ–¥–µ–ª—å
    model_path = os.path.join(model_dir, "wake_word_model.h5")
    model.save(model_path)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ TFLite —Å –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    
    # –í–∫–ª—é—á–∞–µ–º –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    
    # –ü—Ä–æ–±—É–µ–º –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é
    try:
        tflite_model = converter.convert()
        
        tflite_path = os.path.join(model_dir, "wake_word_model.tflite")
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
        size_kb = os.path.getsize(tflite_path) / 1024
        
        print(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä—É—Å—Å–∫–∞—è –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞: {tflite_path}")
        print(f"üìä –†–∞–∑–º–µ—Ä: {size_kb:.1f} KB")
        
        return size_kb
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏: {e}")
        
        # –ü—Ä–æ–±—É–µ–º –±–µ–∑ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏
        print("üîÑ –ü—Ä–æ–±—É–µ–º –±–µ–∑ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏...")
        converter = tf.lite.TFLiteConverter.from_keras_model(model)
        tflite_model = converter.convert()
        
        tflite_path = os.path.join(model_dir, "wake_word_model.tflite")
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        size_kb = os.path.getsize(tflite_path) / 1024
        
        print(f"‚úÖ –†—É—Å—Å–∫–∞—è –º–æ–¥–µ–ª—å –±–µ–∑ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏: {tflite_path}")
        print(f"üìä –†–∞–∑–º–µ—Ä: {size_kb:.1f} KB")
        
        return size_kb

if __name__ == "__main__":
    optimize_ru_model()