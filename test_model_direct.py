#!/usr/bin/env python3
"""
–ü—Ä—è–º–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ microWakeWord
–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ MMAP —Ñ–∞–π–ª–æ–≤
"""

import os
import sys
import numpy as np
import tensorflow as tf
from pathlib import Path
import json
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ
sys.path.append(os.path.join(os.path.dirname(__file__), 'microwakeword'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.utils.path_manager import paths

def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    
    # –ü—É—Ç—å –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏
    weights_path = "/home/microWakeWord_data/trained_models/wakeword/best_weights.weights.h5"
    
    if not os.path.exists(weights_path):
        print(f"‚ùå –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {weights_path}")
        return None
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã microWakeWord
        import microwakeword.mixednet as mixednet
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç flags –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        class Flags:
            def __init__(self):
                self.pointwise_filters = "48,48,48,48"
                self.repeat_in_block = "1,1,1,1"
                self.mixconv_kernel_sizes = "[5],[9],[13],[21]"
                self.residual_connection = "0,0,0,0"
                self.first_conv_filters = 32
                self.first_conv_kernel_size = 3
                self.stride = 1
                self.spatial_attention = False
                self.temporal_attention = False
                self.attention_heads = 1
                self.attention_dim = 64
                self.pooled = False
                self.max_pool = False
        
        flags = Flags()
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        model = mixednet.model(flags, (194, 40), 32)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        model.load_weights(weights_path)
        
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        return model
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        import traceback
        traceback.print_exc()
        return None

def load_mmap_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ MMAP —Ñ–∞–π–ª–æ–≤"""
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ MMAP —Ñ–∞–π–ª–æ–≤...")
    
    try:
        from microwakeword.data import RaggedMmap
        
        # –ü—É—Ç—å –∫ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º –¥–∞–Ω–Ω—ã–º
        positives_path = os.path.join(paths.FEATURES_POSITIVES, "training", "wakeword_mmap")
        
        if not os.path.exists(positives_path):
            print(f"‚ùå –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {positives_path}")
            return None
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        data = RaggedMmap(positives_path)
        
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤")
        return data
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_model_on_data(model, data):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print("üîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    try:
        predictions = []
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –ø–µ—Ä–≤—ã—Ö 100 –æ–±—Ä–∞–∑—Ü–∞—Ö
        test_size = min(100, len(data))
        
        for i in range(test_size):
            # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü
            sample = data[i]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
            if sample.shape[0] != 194:
                # –û–±—Ä–µ–∑–∞–µ–º –∏–ª–∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
                if sample.shape[0] > 194:
                    sample = sample[:194, :]
                else:
                    # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
                    padding = np.zeros((194 - sample.shape[0], 40))
                    sample = np.vstack([sample, padding])
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            if len(sample.shape) == 2:
                # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
                sample = np.expand_dims(sample, axis=0)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            pred = model.predict(sample, verbose=0)
            predictions.append(pred[0][0])
            
            if (i + 1) % 20 == 0:
                print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i + 1}/{test_size} –æ–±—Ä–∞–∑—Ü–æ–≤")
        
        predictions = np.array(predictions)
        
        print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(predictions)} –æ–±—Ä–∞–∑—Ü–æ–≤")
        print(f"üìä –°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {np.mean(predictions):.4f}")
        print(f"üìä –ú–µ–¥–∏–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {np.median(predictions):.4f}")
        print(f"üìä –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {np.min(predictions):.4f}")
        print(f"üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {np.max(predictions):.4f}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ 0.5
        above_threshold = np.sum(predictions > 0.5)
        print(f"üìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π > 0.5: {above_threshold} –∏–∑ {len(predictions)} ({above_threshold/len(predictions)*100:.1f}%)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ 0.9
        above_threshold_90 = np.sum(predictions > 0.9)
        print(f"üìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π > 0.9: {above_threshold_90} –∏–∑ {len(predictions)} ({above_threshold_90/len(predictions)*100:.1f}%)")
        
        return {
            'predictions': predictions,
            'mean_prediction': np.mean(predictions),
            'median_prediction': np.median(predictions),
            'min_prediction': np.min(predictions),
            'max_prediction': np.max(predictions),
            'above_threshold_50': above_threshold,
            'above_threshold_90': above_threshold_90,
            'total_samples': len(predictions)
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
        import traceback
        traceback.print_exc()
        return None

def print_results(results):
    """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫—Ä–∞—Å–∏–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
    print("\n" + "="*60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ú–û–î–ï–õ–ò microWakeWord")
    print("="*60)
    
    print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô:")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:     {results['mean_prediction']:.4f}")
    print(f"   –ú–µ–¥–∏–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:  {results['median_prediction']:.4f}")
    print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {results['min_prediction']:.4f}")
    print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {results['max_prediction']:.4f}")
    
    print(f"\nüéØ –ü–û–†–û–ì–û–í–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø:")
    print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π > 0.5:  {results['above_threshold_50']:4d} –∏–∑ {results['total_samples']:4d} ({results['above_threshold_50']/results['total_samples']*100:.1f}%)")
    print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π > 0.9:  {results['above_threshold_90']:4d} –∏–∑ {results['total_samples']:4d} ({results['above_threshold_90']/results['total_samples']*100:.1f}%)")
    
    print(f"\n‚úÖ –û–¶–ï–ù–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
    
    # –û—Ü–µ–Ω–∫–∞ –ø–æ wake word —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º
    if results['mean_prediction'] > 0.8:
        print(f"   ‚úÖ –°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç–ª–∏—á–Ω–æ–µ (> 0.8)")
    elif results['mean_prediction'] > 0.6:
        print(f"   ‚ö†Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ö–æ—Ä–æ—à–µ–µ (> 0.6)")
    else:
        print(f"   ‚ùå –°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–ª–æ—Ö–æ–µ (< 0.6)")
    
    if results['above_threshold_50']/results['total_samples'] > 0.8:
        print(f"   ‚úÖ –ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –æ—Ç–ª–∏—á–Ω—ã–π (> 80%)")
    elif results['above_threshold_50']/results['total_samples'] > 0.6:
        print(f"   ‚ö†Ô∏è  –ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π —Ö–æ—Ä–æ—à–∏–π (> 60%)")
    else:
        print(f"   ‚ùå –ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –ø–ª–æ—Ö–æ–π (< 60%)")
    
    if results['above_threshold_90']/results['total_samples'] > 0.5:
        print(f"   ‚úÖ –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—Ç–ª–∏—á–Ω–∞—è (> 50%)")
    elif results['above_threshold_90']/results['total_samples'] > 0.3:
        print(f"   ‚ö†Ô∏è  –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ö–æ—Ä–æ—à–∞—è (> 30%)")
    else:
        print(f"   ‚ùå –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–ª–æ—Ö–∞—è (< 30%)")
    
    print("="*60)

def save_results(results):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"/home/microWakeWord_data/model_test_results_{timestamp}.json"
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è JSON
    results_json = {
        'timestamp': timestamp,
        'model_path': '/home/microWakeWord_data/trained_models/wakeword/best_weights.weights.h5',
        'test_type': 'direct_mmap_data',
        'results': {
            'mean_prediction': float(results['mean_prediction']),
            'median_prediction': float(results['median_prediction']),
            'min_prediction': float(results['min_prediction']),
            'max_prediction': float(results['max_prediction']),
            'above_threshold_50': int(results['above_threshold_50']),
            'above_threshold_90': int(results['above_threshold_90']),
            'total_samples': int(results['total_samples'])
        }
    }
    
    with open(results_file, 'w') as f:
        json.dump(results_json, f, indent=2)
    
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_file}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üéØ –ü—Ä—è–º–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ microWakeWord")
    print("="*50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = load_model()
    if model is None:
        return False
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    data = load_mmap_data()
    if data is None:
        return False
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
    results = test_model_on_data(model, data)
    if results is None:
        return False
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print_results(results)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    save_results(results)
    
    print("\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
    return True

if __name__ == "__main__":
    main()