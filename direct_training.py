#!/usr/bin/env python3
"""
–ü—Ä—è–º–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ wake-word –±–µ–∑ microWakeWord
"""

import os
import sys
import numpy as np
import tensorflow as tf
import librosa
from pathlib import Path
import random

def load_audio_file(file_path, target_sr=16000):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª"""
    try:
        audio, sr = librosa.load(file_path, sr=target_sr)
        return audio
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file_path}: {e}")
        return None

def create_mel_spectrogram(audio, sr=16000, n_mels=40, hop_length=160):
    """–°–æ–∑–¥–∞–µ—Ç –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É"""
    try:
        # –°–æ–∑–¥–∞–µ–º –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
        mel_spec = librosa.feature.melspectrogram(
            y=audio, 
            sr=sr, 
            n_mels=n_mels, 
            hop_length=hop_length,
            n_fft=1024
        )
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–π –º–∞—Å—à—Ç–∞–±
        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
        
        # –û–±—Ä–µ–∑–∞–µ–º –∏–ª–∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (49 –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤)
        if mel_spec_db.shape[1] >= 49:
            mel_spec_db = mel_spec_db[:, :49]
        else:
            # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
            padding = np.zeros((n_mels, 49 - mel_spec_db.shape[1]))
            mel_spec_db = np.hstack([mel_spec_db, padding])
        
        return mel_spec_db
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã: {e}")
        return None

def load_dataset(positive_dir, negative_dir, max_samples=100):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç"""
    
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤
    pos_files = list(Path(positive_dir).glob('*.wav'))[:max_samples]
    neg_files = list(Path(negative_dir).glob('*.wav'))[:max_samples]
    
    print(f"–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(pos_files)}")
    print(f"–ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(neg_files)}")
    
    features = []
    labels = []
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã
    print("–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
    for i, file_path in enumerate(pos_files):
        if i % 20 == 0:
            print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{len(pos_files)}")
        
        audio = load_audio_file(file_path)
        if audio is not None:
            mel_spec = create_mel_spectrogram(audio)
            if mel_spec is not None:
                features.append(mel_spec)
                labels.append(1)  # –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Ñ–∞–π–ª—ã
    print("–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
    for i, file_path in enumerate(neg_files):
        if i % 10 == 0:
            print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{len(neg_files)}")
        
        audio = load_audio_file(file_path)
        if audio is not None:
            mel_spec = create_mel_spectrogram(audio)
            if mel_spec is not None:
                features.append(mel_spec)
                labels.append(0)  # –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∫–ª–∞—Å—Å
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(features)} —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º")
    print(f"   –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö: {sum(labels)}")
    print(f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö: {len(labels) - sum(labels)}")
    
    return np.array(features), np.array(labels)

def create_model():
    """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å"""
    
    print("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(40, 49)),  # n_mels x time_steps
        tf.keras.layers.Reshape((40, 49, 1)),
        
        # –°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–ª–æ–∏
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Dropout(0.25),
        
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Dropout(0.25),
        
        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dropout(0.5),
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy', 'precision', 'recall']
    )
    
    print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞!")
    model.summary()
    
    return model

def train_model(model, X, y):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å"""
    
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    print(f"üìä –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X_train.shape}")
    print(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_test.shape}")
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    history = model.fit(
        X_train, y_train,
        epochs=20,
        batch_size=32,
        validation_data=(X_test, y_test),
        verbose=1,
        callbacks=[
            tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),
            tf.keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.5)
        ]
    )
    
    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
    print("\nüìä –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏:")
    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_test, verbose=0)
    
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å: {test_accuracy:.4f}")
    print(f"Precision: {test_precision:.4f}")
    print(f"Recall: {test_recall:.4f}")
    
    return model, history

def save_model(model):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å"""
    
    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    model_dir = "/root/microWakeWord/models/trained_model"
    os.makedirs(model_dir, exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model_path = os.path.join(model_dir, "wake_word_model.h5")
    model.save(model_path)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ TFLite
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    
    tflite_path = os.path.join(model_dir, "wake_word_model.tflite")
    with open(tflite_path, 'wb') as f:
        f.write(tflite_model)
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    print(f"‚úÖ TFLite –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {tflite_path}")
    
    return model_dir

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("üéØ –ü–†–Ø–ú–û–ï –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò WAKE-WORD")
    print("   –¥–ª—è —Ñ—Ä–∞–∑ '–º–æ–π –¥–æ–º' –∏ '–ª—é–±–∏–º—ã–π –¥–æ–º'")
    print("=" * 60)
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        positive_dir = "/root/microWakeWord/piper-sample-generator/positives_combined_aug"
        negative_dir = "/root/microWakeWord/piper-sample-generator/negatives_moy_dom_massive_aug"
        
        X, y = load_dataset(positive_dir, negative_dir, max_samples=200)
        
        if len(X) == 0:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
            return
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        model = create_model()
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        model, history = train_model(model, X, y)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        model_dir = save_model(model)
        
        print("\n" + "=" * 60)
        print("üéâ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print("=" * 60)
        
        print(f"\nüìÅ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {model_dir}")
        print(f"üìä –û–±—É—á–µ–Ω–æ –Ω–∞ {len(X)} —Å—ç–º–ø–ª–∞—Ö")
        print(f"üéØ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ—Ä–∞–∑—ã: '–º–æ–π –¥–æ–º' –∏ '–ª—é–±–∏–º—ã–π –¥–æ–º'")
        print(f"üöÄ –ì–æ—Ç–æ–≤–æ –∫ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()