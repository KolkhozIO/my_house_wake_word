#!/usr/bin/env python3
"""
–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –º–µ—Ç—Ä–∏–∫ –¥–ª—è –º–æ–¥–µ–ª–µ–π microWakeWord
"""

import numpy as np
import json
import yaml
from pathlib import Path
from typing import Dict, List, Any, Tuple
import tensorflow as tf
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report
)
import matplotlib.pyplot as plt
import seaborn as sns


class MetricsCalculator:
    """–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –º–µ—Ç—Ä–∏–∫ –¥–ª—è –º–æ–¥–µ–ª–µ–π wake word"""
    
    def __init__(self, model_path: str = None):
        self.model_path = Path(model_path) if model_path else None
        self.model = None
        self.results = {}
    
    def load_model(self, model_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        self.model_path = Path(model_path)
        
        if self.model_path.suffix == '.tflite':
            self.model = self._load_tflite_model(model_path)
        else:
            self.model = tf.keras.models.load_model(model_path)
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")
    
    def _load_tflite_model(self, model_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ TFLite –º–æ–¥–µ–ª–∏"""
        interpreter = tf.lite.Interpreter(model_path=model_path)
        interpreter.allocate_tensors()
        return interpreter
    
    def calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray, y_prob: np.ndarray = None) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫"""
        print("üìä –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫...")
        
        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='weighted')
        recall = recall_score(y_true, y_pred, average='weighted')
        f1 = f1_score(y_true, y_pred, average='weighted')
        
        # Wake word —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        wake_word_metrics = self._calculate_wake_word_metrics(y_true, y_pred, y_prob)
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
        confusion_mat = confusion_matrix(y_true, y_pred)
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        classification_rep = classification_report(y_true, y_pred, output_dict=True)
        
        # ROC AUC (–µ—Å–ª–∏ –µ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)
        roc_auc = None
        if y_prob is not None:
            try:
                roc_auc = roc_auc_score(y_true, y_prob)
            except ValueError:
                roc_auc = None
        
        metrics = {
            'basic_metrics': {
                'accuracy': float(accuracy),
                'precision': float(precision),
                'recall': float(recall),
                'f1_score': float(f1),
                'roc_auc': float(roc_auc) if roc_auc is not None else None
            },
            'wake_word_metrics': wake_word_metrics,
            'confusion_matrix': confusion_mat.tolist(),
            'classification_report': classification_rep,
            'data_info': {
                'total_samples': len(y_true),
                'positive_samples': int(np.sum(y_true)),
                'negative_samples': int(len(y_true) - np.sum(y_true)),
                'positive_ratio': float(np.sum(y_true) / len(y_true))
            }
        }
        
        return metrics
    
    def _calculate_wake_word_metrics(self, y_true: np.ndarray, y_pred: np.ndarray, y_prob: np.ndarray = None) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç wake word —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        
        # False Reject Rate (FRR) - –ø—Ä–æ–ø—É—Å–∫ wake word
        true_positives = np.sum((y_true == 1) & (y_pred == 1))
        false_negatives = np.sum((y_true == 1) & (y_pred == 0))
        frr = false_negatives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        
        # False Accept Rate (FAR) - –ª–æ–∂–Ω–æ–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–µ
        false_positives = np.sum((y_true == 0) & (y_pred == 1))
        true_negatives = np.sum((y_true == 0) & (y_pred == 0))
        far = false_positives / (false_positives + true_negatives) if (false_positives + true_negatives) > 0 else 0
        
        # False Accepts per Hour (FA/h) - –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è –≤ —á–∞—Å
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º 1 —Å–µ–∫—É–Ω–¥—É –Ω–∞ –æ–±—Ä–∞–∑–µ—Ü
        total_hours = len(y_true) / 3600
        fa_per_hour = false_positives / total_hours if total_hours > 0 else 0
        
        # Precision –∏ Recall –¥–ª—è wake word
        wake_word_precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        wake_word_recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        
        # F1 –¥–ª—è wake word
        wake_word_f1 = 2 * (wake_word_precision * wake_word_recall) / (wake_word_precision + wake_word_recall) if (wake_word_precision + wake_word_recall) > 0 else 0
        
        return {
            'false_reject_rate': float(frr),
            'false_accept_rate': float(far),
            'false_accepts_per_hour': float(fa_per_hour),
            'wake_word_precision': float(wake_word_precision),
            'wake_word_recall': float(wake_word_recall),
            'wake_word_f1': float(wake_word_f1),
            'true_positives': int(true_positives),
            'false_positives': int(false_positives),
            'true_negatives': int(true_negatives),
            'false_negatives': int(false_negatives)
        }
    
    def evaluate_model_performance(self, test_data: Tuple[np.ndarray, np.ndarray], model_path: str = None) -> Dict[str, Any]:
        """–ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        if model_path:
            self.load_model(model_path)
        
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        X_test, y_test = test_data
        
        print(f"üîç –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ {len(X_test)} –æ–±—Ä–∞–∑—Ü–∞—Ö...")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        if isinstance(self.model, tf.lite.Interpreter):
            y_pred, y_prob = self._predict_tflite(X_test)
        else:
            y_prob = self.model.predict(X_test)
            y_pred = (y_prob > 0.5).astype(int).flatten()
            y_prob = y_prob.flatten()
        
        # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
        metrics = self.calculate_metrics(y_test, y_pred, y_prob)
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        performance_analysis = self._analyze_performance(metrics)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = self._generate_recommendations(metrics)
        
        results = {
            'model_path': str(self.model_path) if self.model_path else None,
            'metrics': metrics,
            'performance_analysis': performance_analysis,
            'recommendations': recommendations,
            'evaluation_summary': self._create_summary(metrics, performance_analysis)
        }
        
        return results
    
    def _predict_tflite(self, X_test: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è TFLite –º–æ–¥–µ–ª–∏"""
        input_details = self.model.get_input_details()
        output_details = self.model.get_output_details()
        
        predictions = []
        probabilities = []
        
        for sample in X_test:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            input_data = sample.reshape(input_details[0]['shape']).astype(input_details[0]['dtype'])
            
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            self.model.set_tensor(input_details[0]['index'], input_data)
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
            self.model.invoke()
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            output_data = self.model.get_tensor(output_details[0]['index'])
            probabilities.append(output_data[0])
            predictions.append(1 if output_data[0] > 0.5 else 0)
        
        return np.array(predictions), np.array(probabilities)
    
    def _analyze_performance(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        wake_word_metrics = metrics['wake_word_metrics']
        basic_metrics = metrics['basic_metrics']
        
        analysis = {
            'overall_score': 0,
            'strengths': [],
            'weaknesses': [],
            'performance_level': 'unknown'
        }
        
        # –ê–Ω–∞–ª–∏–∑ FRR (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∏–∑–∫–∏–º)
        frr = wake_word_metrics['false_reject_rate']
        if frr < 0.01:
            analysis['strengths'].append("–û—Ç–ª–∏—á–Ω—ã–π FRR (< 1%)")
            analysis['overall_score'] += 25
        elif frr < 0.05:
            analysis['strengths'].append("–•–æ—Ä–æ—à–∏–π FRR (< 5%)")
            analysis['overall_score'] += 20
        else:
            analysis['weaknesses'].append(f"–í—ã—Å–æ–∫–∏–π FRR ({frr:.1%})")
        
        # –ê–Ω–∞–ª–∏–∑ FA/h (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∏–∑–∫–∏–º)
        fa_per_hour = wake_word_metrics['false_accepts_per_hour']
        if fa_per_hour < 0.5:
            analysis['strengths'].append("–û—Ç–ª–∏—á–Ω—ã–π FA/h (< 0.5)")
            analysis['overall_score'] += 25
        elif fa_per_hour < 2.0:
            analysis['strengths'].append("–•–æ—Ä–æ—à–∏–π FA/h (< 2.0)")
            analysis['overall_score'] += 20
        else:
            analysis['weaknesses'].append(f"–í—ã—Å–æ–∫–∏–π FA/h ({fa_per_hour:.1f})")
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏
        accuracy = basic_metrics['accuracy']
        if accuracy > 0.95:
            analysis['strengths'].append("–í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (> 95%)")
            analysis['overall_score'] += 25
        elif accuracy > 0.90:
            analysis['strengths'].append("–•–æ—Ä–æ—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (> 90%)")
            analysis['overall_score'] += 20
        else:
            analysis['weaknesses'].append(f"–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å ({accuracy:.1%})")
        
        # –ê–Ω–∞–ª–∏–∑ F1 –¥–ª—è wake word
        wake_word_f1 = wake_word_metrics['wake_word_f1']
        if wake_word_f1 > 0.9:
            analysis['strengths'].append("–û—Ç–ª–∏—á–Ω—ã–π F1 –¥–ª—è wake word (> 90%)")
            analysis['overall_score'] += 25
        elif wake_word_f1 > 0.8:
            analysis['strengths'].append("–•–æ—Ä–æ—à–∏–π F1 –¥–ª—è wake word (> 80%)")
            analysis['overall_score'] += 20
        else:
            analysis['weaknesses'].append(f"–ù–∏–∑–∫–∏–π F1 –¥–ª—è wake word ({wake_word_f1:.1%})")
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if analysis['overall_score'] >= 90:
            analysis['performance_level'] = 'excellent'
        elif analysis['overall_score'] >= 75:
            analysis['performance_level'] = 'good'
        elif analysis['overall_score'] >= 60:
            analysis['performance_level'] = 'fair'
        else:
            analysis['performance_level'] = 'poor'
        
        return analysis
    
    def _generate_recommendations(self, metrics: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"""
        recommendations = []
        wake_word_metrics = metrics['wake_word_metrics']
        basic_metrics = metrics['basic_metrics']
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ FRR
        frr = wake_word_metrics['false_reject_rate']
        if frr > 0.05:
            recommendations.append("–í—ã—Å–æ–∫–∏–π FRR - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∏–ª–∏ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ FA/h
        fa_per_hour = wake_word_metrics['false_accepts_per_hour']
        if fa_per_hour > 2.0:
            recommendations.append("–í—ã—Å–æ–∫–∏–π FA/h - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∏–ª–∏ —É–ª—É—á—à–µ–Ω–∏–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏
        accuracy = basic_metrics['accuracy']
        if accuracy < 0.90:
            recommendations.append("–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏ –∏–ª–∏ —É–ª—É—á—à–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–∏—Å–±–∞–ª–∞–Ω—Å—É
        positive_ratio = metrics['data_info']['positive_ratio']
        if positive_ratio < 0.01 or positive_ratio > 0.1:
            recommendations.append("–ù–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å –¥–∞–Ω–Ω—ã—Ö - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ ROC AUC
        roc_auc = basic_metrics['roc_auc']
        if roc_auc is not None and roc_auc < 0.85:
            recommendations.append("–ù–∏–∑–∫–∏–π ROC AUC - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–ª—É—á—à–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏")
        
        return recommendations
    
    def _create_summary(self, metrics: Dict[str, Any], performance_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –æ—Ü–µ–Ω–∫–∏"""
        wake_word_metrics = metrics['wake_word_metrics']
        basic_metrics = metrics['basic_metrics']
        
        return {
            'model_name': self.model_path.name if self.model_path else 'Unknown',
            'overall_score': performance_analysis['overall_score'],
            'performance_level': performance_analysis['performance_level'],
            'key_metrics': {
                'accuracy': basic_metrics['accuracy'],
                'frr': wake_word_metrics['false_reject_rate'],
                'fa_per_hour': wake_word_metrics['false_accepts_per_hour'],
                'wake_word_f1': wake_word_metrics['wake_word_f1']
            },
            'strengths_count': len(performance_analysis['strengths']),
            'weaknesses_count': len(performance_analysis['weaknesses']),
            'recommendations_count': len(self._generate_recommendations(metrics))
        }
    
    def save_results(self, results: Dict[str, Any], output_path: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏"""
        if output_path is None:
            model_name = self.model_path.stem if self.model_path else 'unknown_model'
            output_path = f"tools/model_evaluation/results/{model_name}_evaluation.json"
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ YAML
        yaml_path = output_path.with_suffix('.yaml')
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(results, f, default_flow_style=False, allow_unicode=True)
        
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}, {yaml_path}")
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        summary = results['evaluation_summary']
        metrics = results['metrics']
        wake_word_metrics = metrics['wake_word_metrics']
        basic_metrics = metrics['basic_metrics']
        
        report = f"""
# –û—Ç—á–µ—Ç –ø–æ –æ—Ü–µ–Ω–∫–µ –º–æ–¥–µ–ª–∏: {summary['model_name']}

## üìä –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
- **–û–±—â–∏–π –±–∞–ª–ª**: {summary['overall_score']}/100
- **–£—Ä–æ–≤–µ–Ω—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**: {summary['performance_level'].upper()}
- **–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã**: {summary['strengths_count']}
- **–°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã**: {summary['weaknesses_count']}

## üéØ –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- **–¢–æ—á–Ω–æ—Å—Ç—å**: {summary['key_metrics']['accuracy']:.1%}
- **FRR (False Reject Rate)**: {summary['key_metrics']['frr']:.1%}
- **FA/h (False Accepts per Hour)**: {summary['key_metrics']['fa_per_hour']:.1f}
- **F1 –¥–ª—è wake word**: {summary['key_metrics']['wake_word_f1']:.1%}

## üìà –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- **Precision**: {basic_metrics['precision']:.1%}
- **Recall**: {basic_metrics['recall']:.1%}
- **F1 Score**: {basic_metrics['f1_score']:.1%}
- **ROC AUC**: {basic_metrics['roc_auc']:.3f if basic_metrics['roc_auc'] else 'N/A'}

## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
"""
        
        for i, rec in enumerate(results['recommendations'], 1):
            report += f"{i}. {rec}\n"
        
        return report


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    calculator = MetricsCalculator()
    
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    print("üîç –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –º–µ—Ç—Ä–∏–∫ microWakeWord")
    print("–î–ª—è –ø–æ–ª–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")


if __name__ == "__main__":
    main()