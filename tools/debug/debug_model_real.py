#!/usr/bin/env python3
"""
–†–µ–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏ - –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç
"""

import os
import sys
import numpy as np
import librosa
import soundfile as sf
import tensorflow as tf
from pathlib import Path
import glob
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ microWakeWord
sys.path.append('/home/microWakeWord')
from src.utils.path_manager import paths

def debug_data_distribution():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –î–ê–ù–ù–´–•:")
    print("=" * 50)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    positives_dir = paths.POSITIVES_RAW
    negatives_dir = paths.NEGATIVES_RAW
    
    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª—ã
    positive_files = glob.glob(os.path.join(positives_dir, "*.wav"))
    negative_files = glob.glob(os.path.join(negatives_dir, "*.wav"))
    
    print(f"üìÅ –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(positive_files)}")
    print(f"üìÅ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(negative_files)}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
    print(f"\nüéµ –ê–ù–ê–õ–ò–ó –ü–û–ó–ò–¢–ò–í–ù–´–• –§–ê–ô–õ–û–í:")
    for i, file_path in enumerate(positive_files[:3]):
        try:
            audio, sr = librosa.load(file_path, sr=16000, mono=True)
            duration = len(audio) / sr
            rms = np.sqrt(np.mean(audio**2))
            print(f"  {i+1}. {os.path.basename(file_path)}: {duration:.2f}—Å, RMS: {rms:.3f}")
        except Exception as e:
            print(f"  {i+1}. {os.path.basename(file_path)}: –û–®–ò–ë–ö–ê - {e}")
    
    print(f"\nüéµ –ê–ù–ê–õ–ò–ó –ù–ï–ì–ê–¢–ò–í–ù–´–• –§–ê–ô–õ–û–í:")
    for i, file_path in enumerate(negative_files[:3]):
        try:
            audio, sr = librosa.load(file_path, sr=16000, mono=True)
            duration = len(audio) / sr
            rms = np.sqrt(np.mean(audio**2))
            print(f"  {i+1}. {os.path.basename(file_path)}: {duration:.2f}—Å, RMS: {rms:.3f}")
        except Exception as e:
            print(f"  {i+1}. {os.path.basename(file_path)}: –û–®–ò–ë–ö–ê - {e}")

def create_realistic_model():
    """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—É—é –º–æ–¥–µ–ª—å —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π"""
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(194, 40)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dropout(0.5),  # –°–∏–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model

def preprocess_audio_real(file_path, target_sr=16000, duration_ms=1500):
    """–†–µ–∞–ª—å–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
        audio, sr = librosa.load(file_path, sr=target_sr, mono=True)
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        target_samples = int(duration_ms * target_sr / 1000)
        if len(audio) > target_samples:
            # –°–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            start = np.random.randint(0, len(audio) - target_samples)
            audio = audio[start:start + target_samples]
        else:
            # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π
            audio = np.pad(audio, (0, target_samples - len(audio)))
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
        n_fft = 512
        hop_length = 160
        n_mels = 40
        
        # STFT
        stft = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)
        magnitude = np.abs(stft)
        
        # Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞
        mel_spec = librosa.feature.melspectrogram(
            S=magnitude**2, 
            sr=target_sr, 
            n_mels=n_mels,
            fmax=target_sr//2
        )
        
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (194, 40)
        if log_mel_spec.shape[1] > 194:
            log_mel_spec = log_mel_spec[:, :194]
        else:
            # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
            pad_width = 194 - log_mel_spec.shape[1]
            log_mel_spec = np.pad(log_mel_spec, ((0, 0), (0, pad_width)))
        
        return log_mel_spec.T  # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è (194, 40)
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path}: {e}")
        return None

def test_with_realistic_data():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    print("\nüß™ –†–ï–ê–õ–ò–°–¢–ò–ß–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï:")
    print("=" * 50)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    positives_dir = paths.POSITIVES_RAW
    negatives_dir = paths.NEGATIVES_RAW
    
    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª—ã
    positive_files = glob.glob(os.path.join(positives_dir, "*.wav"))[:50]  # 50 –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö
    negative_files = glob.glob(os.path.join(negatives_dir, "*.wav"))[:50]  # 50 –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö
    
    print(f"üìä –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ {len(positive_files)} –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –∏ {len(negative_files)} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    X = []
    y = []
    
    print("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    for file_path in positive_files:
        spectrogram = preprocess_audio_real(file_path)
        if spectrogram is not None:
            X.append(spectrogram)
            y.append(1)  # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π –∫–ª–∞—Å—Å
    
    for file_path in negative_files:
        spectrogram = preprocess_audio_real(file_path)
        if spectrogram is not None:
            X.append(spectrogram)
            y.append(0)  # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∫–ª–∞—Å—Å
    
    X = np.array(X)
    y = np.array(y)
    
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: {X.shape}, –º–µ—Ç–∫–∏: {y.shape}")
    print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {np.bincount(y)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–∏—è –≤ –¥–∞–Ω–Ω—ã—Ö
    pos_data = X[y == 1]
    neg_data = X[y == 0]
    
    print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ò –î–ê–ù–ù–´–•:")
    print(f"   –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ: mean={np.mean(pos_data):.3f}, std={np.std(pos_data):.3f}")
    print(f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ: mean={np.mean(neg_data):.3f}, std={np.std(neg_data):.3f}")
    print(f"   –†–∞–∑–Ω–∏—Ü–∞: {abs(np.mean(pos_data) - np.mean(neg_data)):.3f}")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    print(f"\nüìä Train: {X_train.shape}, Test: {X_test.shape}")
    print(f"üìä Train labels: {np.bincount(y_train)}")
    print(f"üìä Test labels: {np.bincount(y_test)}")
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    model = create_realistic_model()
    
    # –û–±—É—á–∞–µ–º —Å —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π
    early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True
    )
    
    print(f"\nüèãÔ∏è –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    history = model.fit(
        X_train, y_train,
        epochs=50,
        batch_size=16,
        validation_data=(X_test, y_test),
        callbacks=[early_stopping],
        verbose=1
    )
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_proba = model.predict(X_test)
    y_pred = (y_pred_proba > 0.5).astype(int).flatten()
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    try:
        auc = roc_auc_score(y_test, y_pred_proba)
    except:
        auc = 0.0
    
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    
    # Wake Word —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    frr = fn / (fn + tp) if (fn + tp) > 0 else 0  # False Reject Rate
    far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Accept Rate
    
    print(f"\nüìä –†–ï–ê–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò:")
    print(f"   Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"   Precision: {precision:.4f} ({precision*100:.2f}%)")
    print(f"   Recall:    {recall:.4f} ({recall*100:.2f}%)")
    print(f"   F1-Score:  {f1:.4f} ({f1*100:.2f}%)")
    print(f"   AUC:       {auc:.4f}")
    print(f"   FRR:       {frr:.4f} ({frr*100:.2f}%)")
    print(f"   FAR:       {far:.4f} ({far*100:.2f}%)")
    
    print(f"\nüìä CONFUSION MATRIX:")
    print(f"   True Negatives:  {tn:3d}")
    print(f"   False Positives: {fp:3d}")
    print(f"   False Negatives: {fn:3d}")
    print(f"   True Positives:  {tp:3d}")
    
    # –ê–Ω–∞–ª–∏–∑ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    print(f"\nüéØ –ê–ù–ê–õ–ò–ó –£–í–ï–†–ï–ù–ù–û–°–¢–ò:")
    pos_confidences = y_pred_proba[y_test == 1]
    neg_confidences = y_pred_proba[y_test == 0]
    
    if len(pos_confidences) > 0:
        print(f"   –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ: –º–∏–Ω={np.min(pos_confidences):.3f}, –º–∞–∫—Å={np.max(pos_confidences):.3f}, —Å—Ä–µ–¥–Ω–µ–µ={np.mean(pos_confidences):.3f}")
    if len(neg_confidences) > 0:
        print(f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ: –º–∏–Ω={np.min(neg_confidences):.3f}, –º–∞–∫—Å={np.max(neg_confidences):.3f}, —Å—Ä–µ–¥–Ω–µ–µ={np.mean(neg_confidences):.3f}")
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auc': auc,
        'frr': frr,
        'far': far,
        'confusion_matrix': cm
    }

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –†–ï–ê–õ–¨–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ú–û–î–ï–õ–ò")
    print("=" * 60)
    
    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    debug_data_distribution()
    
    # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    metrics = test_with_realistic_data()
    
    print(f"\nüéâ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if metrics['accuracy'] > 0.95:
        print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å - –≤–æ–∑–º–æ–∂–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ!")
    elif metrics['accuracy'] > 0.85:
        print("‚úÖ –•–æ—Ä–æ—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å - –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    else:
        print("‚ùå –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å - –º–æ–¥–µ–ª—å –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ —É–ª—É—á—à–µ–Ω–∏–∏")

if __name__ == "__main__":
    main()