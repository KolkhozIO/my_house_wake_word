#!/usr/bin/env python3
"""
–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import os
import sys
import numpy as np
import librosa
import soundfile as sf
import tensorflow as tf
from pathlib import Path
import glob
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ microWakeWord
sys.path.append('/home/microWakeWord')
from src.utils.path_manager import paths

def create_simple_model():
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫"""
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(194, 40)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model

def preprocess_audio_for_metrics(file_path, target_sr=16000, duration_ms=1500):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
        audio, sr = librosa.load(file_path, sr=target_sr, mono=True)
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        target_samples = int(duration_ms * target_sr / 1000)
        if len(audio) > target_samples:
            audio = audio[:target_samples]
        else:
            # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π
            audio = np.pad(audio, (0, target_samples - len(audio)))
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
        n_fft = 512
        hop_length = 160
        n_mels = 40
        
        # STFT
        stft = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)
        magnitude = np.abs(stft)
        
        # Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞
        mel_spec = librosa.feature.melspectrogram(
            S=magnitude**2, 
            sr=target_sr, 
            n_mels=n_mels,
            fmax=target_sr//2
        )
        
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (194, 40)
        if log_mel_spec.shape[1] > 194:
            log_mel_spec = log_mel_spec[:, :194]
        else:
            # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
            pad_width = 194 - log_mel_spec.shape[1]
            log_mel_spec = np.pad(log_mel_spec, ((0, 0), (0, pad_width)))
        
        return log_mel_spec.T  # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è (194, 40)
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path}: {e}")
        return None

def prepare_test_data():
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    print("üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    positives_dir = paths.POSITIVES_RAW
    negatives_dir = paths.NEGATIVES_RAW
    
    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª—ã
    positive_files = glob.glob(os.path.join(positives_dir, "*.wav"))[:100]  # 100 –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö
    negative_files = glob.glob(os.path.join(negatives_dir, "*.wav"))[:100]  # 100 –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö
    
    print(f"üìÅ –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(positive_files)}")
    print(f"üìÅ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(negative_files)}")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    X = []
    y = []
    
    print("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    for i, file_path in enumerate(positive_files):
        if i % 20 == 0:
            print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(positive_files)}")
        
        spectrogram = preprocess_audio_for_metrics(file_path)
        if spectrogram is not None:
            X.append(spectrogram)
            y.append(1)  # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π –∫–ª–∞—Å—Å
    
    print("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    for i, file_path in enumerate(negative_files):
        if i % 20 == 0:
            print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(negative_files)}")
        
        spectrogram = preprocess_audio_for_metrics(file_path)
        if spectrogram is not None:
            X.append(spectrogram)
            y.append(0)  # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∫–ª–∞—Å—Å
    
    X = np.array(X)
    y = np.array(y)
    
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: {X.shape}, –º–µ—Ç–∫–∏: {y.shape}")
    print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {np.bincount(y)}")
    
    return X, y

def train_and_evaluate_model(X, y):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –ø–æ–ª—É—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏"""
    print("üèãÔ∏è –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    model = create_simple_model()
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    print(f"üìä Train: {X_train.shape}, Test: {X_test.shape}")
    print(f"üìä Train labels: {np.bincount(y_train)}")
    print(f"üìä Test labels: {np.bincount(y_test)}")
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    history = model.fit(
        X_train, y_train,
        epochs=20,
        batch_size=32,
        validation_data=(X_test, y_test),
        verbose=1
    )
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_proba = model.predict(X_test)
    y_pred = (y_pred_proba > 0.5).astype(int).flatten()
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    try:
        auc = roc_auc_score(y_test, y_pred_proba)
    except:
        auc = 0.0
    
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    
    # Wake Word —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    frr = fn / (fn + tp) if (fn + tp) > 0 else 0  # False Reject Rate
    far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Accept Rate
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auc': auc,
        'frr': frr,
        'far': far,
        'confusion_matrix': cm,
        'history': history
    }

def print_metrics(metrics):
    """–í—ã–≤–æ–¥–∏—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫—Ä–∞—Å–∏–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
    print("\n" + "="*60)
    print("üìä –ö–û–ù–ö–†–ï–¢–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ú–û–î–ï–õ–ò")
    print("="*60)
    
    print(f"üéØ –û–ë–©–ò–ï –ú–ï–¢–†–ò–ö–ò:")
    print(f"   Accuracy:  {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
    print(f"   Precision: {metrics['precision']:.4f} ({metrics['precision']*100:.2f}%)")
    print(f"   Recall:    {metrics['recall']:.4f} ({metrics['recall']*100:.2f}%)")
    print(f"   F1-Score:  {metrics['f1']:.4f} ({metrics['f1']*100:.2f}%)")
    print(f"   AUC:       {metrics['auc']:.4f}")
    
    print(f"\nüé§ WAKE WORD –ú–ï–¢–†–ò–ö–ò:")
    print(f"   FRR (False Reject Rate): {metrics['frr']:.4f} ({metrics['frr']*100:.2f}%)")
    print(f"   FAR (False Accept Rate): {metrics['far']:.4f} ({metrics['far']*100:.2f}%)")
    
    print(f"\nüìä CONFUSION MATRIX:")
    cm = metrics['confusion_matrix']
    print(f"   True Negatives:  {cm[0,0]:3d}")
    print(f"   False Positives: {cm[0,1]:3d}")
    print(f"   False Negatives: {cm[1,0]:3d}")
    print(f"   True Positives:  {cm[1,1]:3d}")
    
    print(f"\nüìà –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø:")
    if metrics['frr'] < 0.05:
        print("   ‚úÖ FRR –æ—Ç–ª–∏—á–Ω—ã–π (< 5%) - –º–æ–¥–µ–ª—å —Ä–µ–¥–∫–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç wake word")
    elif metrics['frr'] < 0.1:
        print("   ‚ö†Ô∏è FRR —Ö–æ—Ä–æ—à–∏–π (< 10%) - –º–æ–¥–µ–ª—å –∏–Ω–æ–≥–¥–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç wake word")
    else:
        print("   ‚ùå FRR –ø–ª–æ—Ö–æ–π (> 10%) - –º–æ–¥–µ–ª—å —á–∞—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç wake word")
    
    if metrics['far'] < 0.02:
        print("   ‚úÖ FAR –æ—Ç–ª–∏—á–Ω—ã–π (< 2%) - –º–æ–¥–µ–ª—å —Ä–µ–¥–∫–æ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞ —Ñ–æ–Ω–µ")
    elif metrics['far'] < 0.05:
        print("   ‚ö†Ô∏è FAR —Ö–æ—Ä–æ—à–∏–π (< 5%) - –º–æ–¥–µ–ª—å –∏–Ω–æ–≥–¥–∞ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞ —Ñ–æ–Ω–µ")
    else:
        print("   ‚ùå FAR –ø–ª–æ—Ö–æ–π (> 5%) - –º–æ–¥–µ–ª—å —á–∞—Å—Ç–æ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞ —Ñ–æ–Ω–µ")
    
    if metrics['accuracy'] > 0.95:
        print("   ‚úÖ Accuracy –æ—Ç–ª–∏—á–Ω—ã–π (> 95%)")
    elif metrics['accuracy'] > 0.90:
        print("   ‚ö†Ô∏è Accuracy —Ö–æ—Ä–æ—à–∏–π (> 90%)")
    else:
        print("   ‚ùå Accuracy –ø–ª–æ—Ö–æ–π (< 90%)")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ü–û–õ–£–ß–ï–ù–ò–ï –ö–û–ù–ö–†–ï–¢–ù–´–• –ú–ï–¢–†–ò–ö –ú–û–î–ï–õ–ò")
    print("="*60)
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    X, y = prepare_test_data()
    
    if len(X) == 0:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        return
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –∏ –ø–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics = train_and_evaluate_model(X, y)
    
    # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏
    print_metrics(metrics)
    
    print(f"\nüéâ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"üìä –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(X)} —Ñ–∞–π–ª–æ–≤")
    print(f"üéØ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")

if __name__ == "__main__":
    main()