#!/usr/bin/env python3
"""
ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
"""

import tensorflow as tf
import numpy as np
import os
import librosa
from pathlib import Path

def load_audio_file(file_path):
    """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ Ñ„Ð°Ð¹Ð»"""
    try:
        audio, sr = librosa.load(file_path, sr=16000)
        return audio
    except Exception as e:
        print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ {file_path}: {e}")
        return None

def create_mel_spectrogram(audio):
    """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ mel-ÑÐ¿ÐµÐºÑ‚Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñƒ"""
    try:
        # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð»Ð¸Ð½Ñ‹ Ð´Ð¾ 1.5 ÑÐµÐºÑƒÐ½Ð´ (24000 ÑÑÐ¼Ð¿Ð»Ð¾Ð² Ð¿Ñ€Ð¸ 16kHz)
        target_length = 24000
        if len(audio) > target_length:
            audio = audio[:target_length]
        else:
            audio = np.pad(audio, (0, target_length - len(audio)))
        
        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ mel-ÑÐ¿ÐµÐºÑ‚Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸
        mel_spec = librosa.feature.melspectrogram(
            y=audio,
            sr=16000,
            n_mels=40,
            hop_length=160,
            n_fft=512
        )
        
        # Ð›Ð¾Ð³Ð°Ñ€Ð¸Ñ„Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
        
        # ÐžÐ±Ñ€ÐµÐ·Ð°ÐµÐ¼ Ð´Ð¾ Ð½ÑƒÐ¶Ð½Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° (40 x 49)
        if mel_spec.shape[1] > 49:
            mel_spec = mel_spec[:, :49]
        elif mel_spec.shape[1] < 49:
            mel_spec = np.pad(mel_spec, ((0, 0), (0, 49 - mel_spec.shape[1])))
        
        return mel_spec
    except Exception as e:
        print(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÐ¿ÐµÐºÑ‚Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹: {e}")
        return None

def load_real_data():
    """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ"""
    features = []
    labels = []
    
    # ÐŸÐ¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÑÐ¼Ð¿Ð»Ñ‹
    pos_dir = Path("piper-sample-generator/positives_combined_aug")
    if pos_dir.exists():
        pos_files = list(pos_dir.glob("*.wav"))
        print(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(pos_files)} Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²")
        
        for i, file_path in enumerate(pos_files[:100]):  # Ð‘ÐµÑ€ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 100
            if i % 10 == 0:
                print(f"ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ: {i}/{min(100, len(pos_files))}")
            
            audio = load_audio_file(file_path)
            if audio is not None:
                mel_spec = create_mel_spectrogram(audio)
                if mel_spec is not None:
                    features.append(mel_spec)
                    labels.append(1)  # Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ
    
    # ÐÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ ÑÑÐ¼Ð¿Ð»Ñ‹
    neg_dir = Path("piper-sample-generator/negatives_moy_dom_massive_aug")
    if neg_dir.exists():
        neg_files = list(neg_dir.glob("*.wav"))
        print(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(neg_files)} Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²")
        
        for i, file_path in enumerate(neg_files[:50]):  # Ð‘ÐµÑ€ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 50
            if i % 10 == 0:
                print(f"ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ: {i}/{min(50, len(neg_files))}")
            
            audio = load_audio_file(file_path)
            if audio is not None:
                mel_spec = create_mel_spectrogram(audio)
                if mel_spec is not None:
                    features.append(mel_spec)
                    labels.append(0)  # Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ
    
    print(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(features)} ÑÐ¿ÐµÐºÑ‚Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼")
    print(f"   ÐŸÐ¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ…: {sum(labels)}")
    print(f"   ÐÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ñ…: {len(labels) - sum(labels)}")
    
    return np.array(features), np.array(labels)

def create_model():
    """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ"""
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(40, 49)),
        tf.keras.layers.Reshape((40, 49, 1)),
        
        tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        
        tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(16, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model

def main():
    """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ"""
    print("ðŸ“¦ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ...")
    features, labels = load_real_data()
    
    if len(features) == 0:
        print("âŒ ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ!")
        return
    
    print("ðŸ—ï¸ Ð¡Ð¾Ð·Ð´Ð°ÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ...")
    model = create_model()
    
    print("ðŸŽ¯ ÐžÐ±ÑƒÑ‡Ð°ÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ...")
    model.fit(features, labels, epochs=10, validation_split=0.2, verbose=1)
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    model_dir = "models/trained_model"
    os.makedirs(model_dir, exist_ok=True)
    
    # H5 Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    model_path = os.path.join(model_dir, "wake_word_model.h5")
    model.save(model_path)
    
    # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² TFLite
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    
    tflite_path = os.path.join(model_dir, "wake_word_model.tflite")
    with open(tflite_path, 'wb') as f:
        f.write(tflite_model)
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€
    size_kb = os.path.getsize(tflite_path) / 1024
    
    print(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð° Ð½Ð° Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…!")
    print(f"ðŸ“Š Ð Ð°Ð·Ð¼ÐµÑ€: {size_kb:.1f} KB")
    print(f"ðŸ“ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð°: {tflite_path}")

if __name__ == "__main__":
    main()