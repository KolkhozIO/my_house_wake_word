#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ microWakeWord —Ç–æ–ª—å–∫–æ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import os
import sys
import numpy as np
import tensorflow as tf
from pathlib import Path
import json
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ
sys.path.append(os.path.join(os.path.dirname(__file__), 'microwakeword'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.utils.path_manager import paths

def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    
    # –ü—É—Ç—å –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏
    weights_path = "/home/microWakeWord_data/trained_models/wakeword/best_weights.weights.h5"
    
    if not os.path.exists(weights_path):
        print(f"‚ùå –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {weights_path}")
        return None
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã microWakeWord
        import microwakeword.mixednet as mixednet
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç flags –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        class Flags:
            def __init__(self):
                self.pointwise_filters = "48,48,48,48"
                self.repeat_in_block = "1,1,1,1"
                self.mixconv_kernel_sizes = "[5],[9],[13],[21]"
                self.residual_connection = "0,0,0,0"
                self.first_conv_filters = 32
                self.first_conv_kernel_size = 3
                self.stride = 1
                self.spatial_attention = False
                self.temporal_attention = False
                self.attention_heads = 1
                self.attention_dim = 64
                self.pooled = False
                self.max_pool = False
        
        flags = Flags()
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        model = mixednet.model(flags, (194, 40), 32)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        model.load_weights(weights_path)
        
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        return model
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        import traceback
        traceback.print_exc()
        return None

def load_positive_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    try:
        import microwakeword.data as input_data
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö
        data_processor = input_data.FeatureHandler({
            'features': [
                {
                    'features_dir': paths.FEATURES_POSITIVES,
                    'penalty_weight': 1.0,
                    'sampling_weight': 1.0,
                    'truncation_strategy': 'random',
                    'truth': True,
                    'type': 'mmap'
                }
            ],
            'batch_size': 32,
            'training_input_shape': (194, 40),
            'stride': 1,
            'window_step_ms': 10
        })
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        test_data = data_processor.get_data(mode="train", batch_size=32, features_length=194)
        
        print(f"‚úÖ –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        return test_data
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_model_on_positives(model, test_data):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    print("üîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    try:
        predictions = []
        true_labels = []
        
        batch_count = 0
        for batch_x, batch_y in test_data:
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            batch_pred = model.predict(batch_x, verbose=0)
            predictions.extend(batch_pred.flatten())
            true_labels.extend(batch_y.flatten())
            
            batch_count += 1
            if batch_count >= 10:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π –¥–ª—è —Ç–µ—Å—Ç–∞
                break
        
        predictions = np.array(predictions)
        true_labels = np.array(true_labels)
        
        print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(predictions)} –æ–±—Ä–∞–∑—Ü–æ–≤")
        print(f"üìä –°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {np.mean(predictions):.4f}")
        print(f"üìä –ú–µ–¥–∏–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {np.median(predictions):.4f}")
        print(f"üìä –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {np.min(predictions):.4f}")
        print(f"üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {np.max(predictions):.4f}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ 0.5
        above_threshold = np.sum(predictions > 0.5)
        print(f"üìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π > 0.5: {above_threshold} –∏–∑ {len(predictions)} ({above_threshold/len(predictions)*100:.1f}%)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ 0.9
        above_threshold_90 = np.sum(predictions > 0.9)
        print(f"üìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π > 0.9: {above_threshold_90} –∏–∑ {len(predictions)} ({above_threshold_90/len(predictions)*100:.1f}%)")
        
        return {
            'predictions': predictions,
            'true_labels': true_labels,
            'mean_prediction': np.mean(predictions),
            'median_prediction': np.median(predictions),
            'min_prediction': np.min(predictions),
            'max_prediction': np.max(predictions),
            'above_threshold_50': above_threshold,
            'above_threshold_90': above_threshold_90,
            'total_samples': len(predictions)
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
        import traceback
        traceback.print_exc()
        return None

def print_results(results):
    """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫—Ä–∞—Å–∏–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
    print("\n" + "="*60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ú–û–î–ï–õ–ò –ù–ê –ü–û–ó–ò–¢–ò–í–ù–´–• –î–ê–ù–ù–´–•")
    print("="*60)
    
    print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô:")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:     {results['mean_prediction']:.4f}")
    print(f"   –ú–µ–¥–∏–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:  {results['median_prediction']:.4f}")
    print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {results['min_prediction']:.4f}")
    print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {results['max_prediction']:.4f}")
    
    print(f"\nüéØ –ü–û–†–û–ì–û–í–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø:")
    print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π > 0.5:  {results['above_threshold_50']:4d} –∏–∑ {results['total_samples']:4d} ({results['above_threshold_50']/results['total_samples']*100:.1f}%)")
    print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π > 0.9:  {results['above_threshold_90']:4d} –∏–∑ {results['total_samples']:4d} ({results['above_threshold_90']/results['total_samples']*100:.1f}%)")
    
    print(f"\n‚úÖ –û–¶–ï–ù–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
    
    # –û—Ü–µ–Ω–∫–∞ –ø–æ wake word —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º
    if results['mean_prediction'] > 0.8:
        print(f"   ‚úÖ –°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç–ª–∏—á–Ω–æ–µ (> 0.8)")
    elif results['mean_prediction'] > 0.6:
        print(f"   ‚ö†Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ö–æ—Ä–æ—à–µ–µ (> 0.6)")
    else:
        print(f"   ‚ùå –°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–ª–æ—Ö–æ–µ (< 0.6)")
    
    if results['above_threshold_50']/results['total_samples'] > 0.8:
        print(f"   ‚úÖ –ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –æ—Ç–ª–∏—á–Ω—ã–π (> 80%)")
    elif results['above_threshold_50']/results['total_samples'] > 0.6:
        print(f"   ‚ö†Ô∏è  –ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π —Ö–æ—Ä–æ—à–∏–π (> 60%)")
    else:
        print(f"   ‚ùå –ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –ø–ª–æ—Ö–æ–π (< 60%)")
    
    if results['above_threshold_90']/results['total_samples'] > 0.5:
        print(f"   ‚úÖ –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—Ç–ª–∏—á–Ω–∞—è (> 50%)")
    elif results['above_threshold_90']/results['total_samples'] > 0.3:
        print(f"   ‚ö†Ô∏è  –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ö–æ—Ä–æ—à–∞—è (> 30%)")
    else:
        print(f"   ‚ùå –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–ª–æ—Ö–∞—è (< 30%)")
    
    print("="*60)

def save_results(results):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"/home/microWakeWord_data/model_test_results_{timestamp}.json"
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è JSON
    results_json = {
        'timestamp': timestamp,
        'model_path': '/home/microWakeWord_data/trained_models/wakeword/best_weights.weights.h5',
        'test_type': 'positive_data_only',
        'results': {
            'mean_prediction': float(results['mean_prediction']),
            'median_prediction': float(results['median_prediction']),
            'min_prediction': float(results['min_prediction']),
            'max_prediction': float(results['max_prediction']),
            'above_threshold_50': int(results['above_threshold_50']),
            'above_threshold_90': int(results['above_threshold_90']),
            'total_samples': int(results['total_samples'])
        }
    }
    
    with open(results_file, 'w') as f:
        json.dump(results_json, f, indent=2)
    
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_file}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üéØ –ü—Ä–æ—Å—Ç–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ microWakeWord –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    print("="*70)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = load_model()
    if model is None:
        return False
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_data = load_positive_data()
    if test_data is None:
        return False
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
    results = test_model_on_positives(model, test_data)
    if results is None:
        return False
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print_results(results)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    save_results(results)
    
    print("\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
    return True

if __name__ == "__main__":
    main()