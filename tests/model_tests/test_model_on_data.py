#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import os
import sys
import numpy as np
import librosa
import soundfile as sf
import tensorflow as tf
from pathlib import Path
import glob

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ microWakeWord
sys.path.append('/home/microWakeWord')
from src.utils.path_manager import paths

def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    model_path = "/home/microWakeWord_data/trained_models/wakeword_mixed_–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π"
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config_path = os.path.join(model_path, "training_config.yaml")
    print(f"üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {config_path}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
    weights_path = os.path.join(model_path, "best_weights.weights.h5")
    print(f"‚öñÔ∏è –í–µ—Å–∞ –º–æ–¥–µ–ª–∏: {weights_path}")
    
    # –°–æ–∑–¥–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ summary: (194, 40) -> 7760
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(194, 40)),
        tf.keras.layers.Flatten(),  # 194 * 40 = 7760
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
    if os.path.exists(weights_path):
        try:
            model.load_weights(weights_path)
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤: {e}")
            print("üîÑ –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –±–µ–∑ –≤–µ—Å–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –±–µ–∑ –≤–µ—Å–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    else:
        print("‚ùå –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return None
    
    return model

def preprocess_audio(file_path, target_sr=16000, duration_ms=1500):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
        audio, sr = librosa.load(file_path, sr=target_sr, mono=True)
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        target_samples = int(duration_ms * target_sr / 1000)
        if len(audio) > target_samples:
            audio = audio[:target_samples]
        else:
            # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π
            audio = np.pad(audio, (0, target_samples - len(audio)))
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        # –í —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        stft = librosa.stft(audio, n_fft=512, hop_length=160)
        magnitude = np.abs(stft)
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (194, 40)
        if magnitude.shape[0] > 40:
            magnitude = magnitude[:40, :]
        if magnitude.shape[1] > 194:
            magnitude = magnitude[:, :194]
        else:
            # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
            pad_width = 194 - magnitude.shape[1]
            magnitude = np.pad(magnitude, ((0, 0), (0, pad_width)))
        
        return magnitude.T  # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è (194, 40)
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path}: {e}")
        return None

def test_model_on_files(model, file_paths, expected_label, label_name):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ —Å–ø–∏—Å–∫–µ —Ñ–∞–π–ª–æ–≤"""
    print(f"\nüéØ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {label_name} –¥–∞–Ω–Ω—ã—Ö:")
    print(f"üìÅ –§–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {len(file_paths)}")
    
    results = []
    
    for i, file_path in enumerate(file_paths[:10]):  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 10 —Ñ–∞–π–ª–æ–≤
        print(f"  üìÑ {i+1}/10: {os.path.basename(file_path)}")
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
        spectrogram = preprocess_audio(file_path)
        if spectrogram is None:
            continue
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏
        input_data = np.expand_dims(spectrogram, axis=0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        try:
            prediction = model.predict(input_data, verbose=0)
            confidence = float(prediction[0][0])
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å
            predicted_class = 1 if confidence > 0.5 else 0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
            is_correct = predicted_class == expected_label
            
            results.append({
                'file': os.path.basename(file_path),
                'confidence': confidence,
                'predicted': predicted_class,
                'expected': expected_label,
                'correct': is_correct
            })
            
            status = "‚úÖ" if is_correct else "‚ùå"
            print(f"    {status} Confidence: {confidence:.3f}, Predicted: {predicted_class}, Expected: {expected_label}")
            
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
    
    return results

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò –ù–ê –ü–†–ò–ú–ï–†–ê–• –î–ê–ù–ù–´–•")
    print("=" * 50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = load_model()
    if model is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    positives_dir = paths.POSITIVES_RAW
    negatives_dir = paths.NEGATIVES_RAW
    
    print(f"üìÅ –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {positives_dir}")
    print(f"üìÅ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {negatives_dir}")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤
    positive_files = glob.glob(os.path.join(positives_dir, "*.wav"))[:10]
    negative_files = glob.glob(os.path.join(negatives_dir, "*.wav"))[:10]
    
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(positive_files)}")
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(negative_files)}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    positive_results = test_model_on_files(model, positive_files, 1, "–ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    negative_results = test_model_on_files(model, negative_files, 0, "–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    print("=" * 50)
    
    # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if positive_results:
        correct_positives = sum(1 for r in positive_results if r['correct'])
        total_positives = len(positive_results)
        avg_confidence_positives = np.mean([r['confidence'] for r in positive_results])
        
        print(f"‚úÖ –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
        print(f"   –ü—Ä–∞–≤–∏–ª—å–Ω–æ: {correct_positives}/{total_positives} ({correct_positives/total_positives*100:.1f}%)")
        print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence_positives:.3f}")
    
    # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if negative_results:
        correct_negatives = sum(1 for r in negative_results if r['correct'])
        total_negatives = len(negative_results)
        avg_confidence_negatives = np.mean([r['confidence'] for r in negative_results])
        
        print(f"‚ùå –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
        print(f"   –ü—Ä–∞–≤–∏–ª—å–Ω–æ: {correct_negatives}/{total_negatives} ({correct_negatives/total_negatives*100:.1f}%)")
        print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence_negatives:.3f}")
    
    # –û–±—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    all_results = positive_results + negative_results
    if all_results:
        total_correct = sum(1 for r in all_results if r['correct'])
        total_tests = len(all_results)
        overall_accuracy = total_correct / total_tests * 100
        
        print(f"\nüéØ –û–ë–©–ê–Ø –¢–û–ß–ù–û–°–¢–¨: {total_correct}/{total_tests} ({overall_accuracy:.1f}%)")
        
        # –ê–Ω–∞–ª–∏–∑ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        positive_confidences = [r['confidence'] for r in positive_results]
        negative_confidences = [r['confidence'] for r in negative_results]
        
        if positive_confidences:
            print(f"üìà –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ: –º–∏–Ω={min(positive_confidences):.3f}, –º–∞–∫—Å={max(positive_confidences):.3f}")
        if negative_confidences:
            print(f"üìâ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ: –º–∏–Ω={min(negative_confidences):.3f}, –º–∞–∫—Å={max(negative_confidences):.3f}")

if __name__ == "__main__":
    main()