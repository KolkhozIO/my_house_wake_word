#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import os
import sys
import numpy as np
import librosa
import soundfile as sf
import tensorflow as tf
from pathlib import Path
import glob

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ microWakeWord
sys.path.append('/home/microWakeWord')
from src.utils.path_manager import paths

def analyze_audio_files(file_paths, label_name):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã –±–µ–∑ –º–æ–¥–µ–ª–∏"""
    print(f"\nüéØ –ê–Ω–∞–ª–∏–∑ {label_name} –¥–∞–Ω–Ω—ã—Ö:")
    print(f"üìÅ –§–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(file_paths)}")
    
    results = []
    
    for i, file_path in enumerate(file_paths[:5]):  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 5 —Ñ–∞–π–ª–æ–≤
        print(f"  üìÑ {i+1}/5: {os.path.basename(file_path)}")
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            audio, sr = librosa.load(file_path, sr=16000, mono=True)
            duration = len(audio) / sr
            
            # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
            rms = np.sqrt(np.mean(audio**2))
            zero_crossings = np.sum(librosa.zero_crossings(audio))
            spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr))
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
            stft = librosa.stft(audio, n_fft=512, hop_length=160)
            magnitude = np.abs(stft)
            
            # Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞
            mel_spec = librosa.feature.melspectrogram(
                S=magnitude**2, 
                sr=sr, 
                n_mels=40,
                fmax=sr//2
            )
            
            log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
            
            results.append({
                'file': os.path.basename(file_path),
                'duration': duration,
                'rms': rms,
                'zero_crossings': zero_crossings,
                'spectral_centroid': spectral_centroid,
                'mel_shape': log_mel_spec.shape,
                'mel_mean': np.mean(log_mel_spec),
                'mel_std': np.std(log_mel_spec)
            })
            
            print(f"    üìä –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.2f}—Å, RMS: {rms:.3f}, ZC: {zero_crossings}")
            print(f"    üìà Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞: {log_mel_spec.shape}, mean: {np.mean(log_mel_spec):.2f}")
            
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
    
    return results

def check_model_files():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏"""
    model_path = "/home/microWakeWord_data/trained_models/wakeword_mixed_–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π"
    
    print("üîç –ü–†–û–í–ï–†–ö–ê –§–ê–ô–õ–û–í –ú–û–î–ï–õ–ò:")
    print("=" * 40)
    
    files_to_check = [
        "best_weights.weights.h5",
        "last_weights.weights.h5", 
        "training_config.yaml",
        "model_summary.txt"
    ]
    
    for filename in files_to_check:
        filepath = os.path.join(model_path, filename)
        if os.path.exists(filepath):
            size = os.path.getsize(filepath)
            print(f"‚úÖ {filename}: {size:,} bytes")
        else:
            print(f"‚ùå {filename}: –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    dirs_to_check = ["logs", "train", "restore"]
    for dirname in dirs_to_check:
        dirpath = os.path.join(model_path, dirname)
        if os.path.exists(dirpath):
            files_count = len(os.listdir(dirpath))
            print(f"üìÅ {dirname}/: {files_count} —Ñ–∞–π–ª–æ–≤")
        else:
            print(f"‚ùå {dirname}/: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
    print("üöÄ –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• –ò –ú–û–î–ï–õ–ò")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏
    check_model_files()
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    positives_dir = paths.POSITIVES_RAW
    negatives_dir = paths.NEGATIVES_RAW
    
    print(f"\nüìÅ –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {positives_dir}")
    print(f"üìÅ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {negatives_dir}")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤
    positive_files = glob.glob(os.path.join(positives_dir, "*.wav"))[:5]
    negative_files = glob.glob(os.path.join(negatives_dir, "*.wav"))[:5]
    
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(positive_files)}")
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(negative_files)}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    positive_results = analyze_audio_files(positive_files, "–ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    negative_results = analyze_audio_files(negative_files, "–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö")
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüìä –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó:")
    print("=" * 50)
    
    if positive_results and negative_results:
        # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        pos_durations = [r['duration'] for r in positive_results]
        neg_durations = [r['duration'] for r in negative_results]
        
        print(f"‚è±Ô∏è –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:")
        print(f"   –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ: {np.mean(pos_durations):.2f}¬±{np.std(pos_durations):.2f}—Å")
        print(f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ: {np.mean(neg_durations):.2f}¬±{np.std(neg_durations):.2f}—Å")
        
        # RMS (–≥—Ä–æ–º–∫–æ—Å—Ç—å)
        pos_rms = [r['rms'] for r in positive_results]
        neg_rms = [r['rms'] for r in negative_results]
        
        print(f"üîä RMS (–≥—Ä–æ–º–∫–æ—Å—Ç—å):")
        print(f"   –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ: {np.mean(pos_rms):.3f}¬±{np.std(pos_rms):.3f}")
        print(f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ: {np.mean(neg_rms):.3f}¬±{np.std(neg_rms):.3f}")
        
        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π —Ü–µ–Ω—Ç—Ä–æ–∏–¥
        pos_centroid = [r['spectral_centroid'] for r in positive_results]
        neg_centroid = [r['spectral_centroid'] for r in negative_results]
        
        print(f"üéµ –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π —Ü–µ–Ω—Ç—Ä–æ–∏–¥:")
        print(f"   –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ: {np.mean(pos_centroid):.0f}¬±{np.std(pos_centroid):.0f}Hz")
        print(f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ: {np.mean(neg_centroid):.0f}¬±{np.std(neg_centroid):.0f}Hz")
        
        # Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã
        pos_mel_mean = [r['mel_mean'] for r in positive_results]
        neg_mel_mean = [r['mel_mean'] for r in negative_results]
        
        print(f"üìä Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞ (—Å—Ä–µ–¥–Ω–µ–µ):")
        print(f"   –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ: {np.mean(pos_mel_mean):.2f}¬±{np.std(pos_mel_mean):.2f}")
        print(f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ: {np.mean(neg_mel_mean):.2f}¬±{np.std(neg_mel_mean):.2f}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–∏—è
        print(f"\nüîç –†–ê–ó–õ–ò–ß–ò–Ø:")
        duration_diff = abs(np.mean(pos_durations) - np.mean(neg_durations))
        rms_diff = abs(np.mean(pos_rms) - np.mean(neg_rms))
        centroid_diff = abs(np.mean(pos_centroid) - np.mean(neg_centroid))
        mel_diff = abs(np.mean(pos_mel_mean) - np.mean(neg_mel_mean))
        
        print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration_diff:.2f}—Å {'‚úÖ' if duration_diff > 0.1 else '‚ö†Ô∏è'}")
        print(f"   RMS: {rms_diff:.3f} {'‚úÖ' if rms_diff > 0.01 else '‚ö†Ô∏è'}")
        print(f"   –¶–µ–Ω—Ç—Ä–æ–∏–¥: {centroid_diff:.0f}Hz {'‚úÖ' if centroid_diff > 100 else '‚ö†Ô∏è'}")
        print(f"   Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞: {mel_diff:.2f} {'‚úÖ' if mel_diff > 1.0 else '‚ö†Ô∏è'}")

if __name__ == "__main__":
    main()