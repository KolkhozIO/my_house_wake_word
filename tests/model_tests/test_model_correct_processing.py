#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–∞–Ω–Ω—ã—Ö (MicroFrontend)
"""

import os
import sys
import numpy as np
import tensorflow as tf
import yaml
import logging
from pathlib import Path
import random

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    logger.info("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config_path = '/home/microWakeWord_data/training_parameters.yaml'
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        from microwakeword.mixednet import model
        
        class Flags:
            def __init__(self, config):
                self.pointwise_filters = config.get('pointwise_filters', '48, 48, 48, 48')
                self.repeat_in_block = config.get('repeat_in_block', '1, 1, 1, 1')
                self.mixconv_kernel_sizes = config.get('mixconv_kernel_sizes', '[5], [9], [13], [21]')
                self.residual_connection = config.get('residual_connection', '0,0,0,0')
                self.max_pool = config.get('max_pool', 0)
                self.first_conv_filters = config.get('first_conv_filters', 32)
                self.first_conv_kernel_size = config.get('first_conv_kernel_size', 3)
                self.spatial_attention = config.get('spatial_attention', 0)
                self.pooled = config.get('pooled', 0)
                self.stride = config.get('stride', 1)
        
        flags = Flags(config)
        
        # –î–æ–±–∞–≤–ª—è–µ–º spectrogram_length
        from microwakeword.mixednet import spectrogram_slices_dropped
        config['spectrogram_length_final_layer'] = config.get('spectrogram_length_final_layer', 226)
        config['spectrogram_length'] = config['spectrogram_length_final_layer'] + spectrogram_slices_dropped(flags)
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º–æ–π
        from microwakeword.layers import modes
        config['training_input_shape'] = modes.get_input_data_shape(config, modes.Modes.TRAINING)
        
        model_instance = model(flags, shape=config['training_input_shape'], batch_size=1)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à–∏–µ –≤–µ—Å–∞
        weights_path = '/home/microWakeWord_data/original_library_model_best_weights.weights.h5'
        model_instance.load_weights(weights_path)
        
        logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        return model_instance, config
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None, None

def load_audio_file_microfrontend(file_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É –∏—Å–ø–æ–ª—å–∑—É—è MicroFrontend"""
    try:
        import librosa
        from pymicro_features import MicroFrontend
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
        audio, sr = librosa.load(file_path, sr=16000)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ int16 –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–µ
        if audio.dtype in (np.float32, np.float64):
            audio = np.clip((audio * 32768), -32768, 32767).astype(np.int16)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º MicroFrontend –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–µ
        audio_bytes = audio.tobytes()
        micro_frontend = MicroFrontend()
        features = []
        audio_idx = 0
        num_audio_bytes = len(audio_bytes)
        
        while audio_idx + 160 * 2 < num_audio_bytes:
            frontend_result = micro_frontend.ProcessSamples(
                audio_bytes[audio_idx : audio_idx + 160 * 2]
            )
            audio_idx += frontend_result.samples_read * 2
            if frontend_result.features:
                features.append(frontend_result.features)
        
        if not features:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ {file_path}")
            return None
        
        spectrogram = np.array(features).astype(np.float32)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–µ
        spectrogram = (spectrogram - spectrogram.mean()) / spectrogram.std()
        
        return spectrogram
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ {file_path}: {e}")
        return None

def test_model_on_files(model, config, test_files, expected_label, test_name):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –Ω–∞–±–æ—Ä–µ —Ñ–∞–π–ª–æ–≤"""
    logger.info(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {test_name} ({len(test_files)} —Ñ–∞–π–ª–æ–≤)")
    
    correct_predictions = 0
    total_predictions = 0
    predictions = []
    
    for file_path in test_files:
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
            spectrogram = load_audio_file_microfrontend(file_path)
            if spectrogram is None:
                continue
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏
            target_length = config['training_input_shape'][0]
            if spectrogram.shape[0] > target_length:
                spectrogram = spectrogram[:target_length]
            elif spectrogram.shape[0] < target_length:
                # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
                padding = np.zeros((target_length - spectrogram.shape[0], spectrogram.shape[1]))
                spectrogram = np.concatenate([spectrogram, padding], axis=0)
            
            # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
            spectrogram = np.expand_dims(spectrogram, axis=0)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            prediction = model.predict(spectrogram, verbose=0)
            predicted_label = 1 if prediction[0][0] > 0.5 else 0
            
            predictions.append(prediction[0][0])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
            if predicted_label == expected_label:
                correct_predictions += 1
            total_predictions += 1
            
            logger.info(f"üìÅ {os.path.basename(file_path)}: {prediction[0][0]:.4f} -> {predicted_label} (–æ–∂–∏–¥–∞–ª–æ—Å—å: {expected_label})")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            continue
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
    avg_confidence = np.mean(predictions) if predictions else 0
    
    logger.info(f"üìä {test_name} —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    logger.info(f"   –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {correct_predictions}/{total_predictions}")
    logger.info(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2%}")
    logger.info(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.4f}")
    
    return accuracy, avg_confidence, predictions

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logger.info("üéØ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò –° –ü–†–ê–í–ò–õ–¨–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–û–ô –î–ê–ù–ù–´–•")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model, config = load_model()
    if model is None:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
        return
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
    positives_dir = "/home/microWakeWord_data/positives_final"
    negatives_dir = "/home/microWakeWord_data/negatives_real"
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤
    positive_files = [os.path.join(positives_dir, f) for f in os.listdir(positives_dir) if f.endswith('.wav')]
    negative_files = [os.path.join(negatives_dir, f) for f in os.listdir(negatives_dir) if f.endswith('.wav')]
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_positive_count = min(20, len(positive_files))
    test_negative_count = min(50, len(negative_files))
    
    test_positive_files = random.sample(positive_files, test_positive_count)
    test_negative_files = random.sample(negative_files, test_negative_count)
    
    logger.info(f"üìÅ –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {len(test_positive_files)}")
    logger.info(f"üìÅ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {len(test_negative_files)}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    pos_accuracy, pos_confidence, pos_predictions = test_model_on_files(
        model, config, test_positive_files, 1, "–ü–û–ó–ò–¢–ò–í–ù–´–ï –î–ê–ù–ù–´–ï (TTS)"
    )
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    neg_accuracy, neg_confidence, neg_predictions = test_model_on_files(
        model, config, test_negative_files, 0, "–ù–ï–ì–ê–¢–ò–í–ù–´–ï –î–ê–ù–ù–´–ï (–†–ï–ê–õ–¨–ù–´–ï)"
    )
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_correct = (pos_accuracy * len(test_positive_files)) + (neg_accuracy * len(test_negative_files))
    total_files = len(test_positive_files) + len(test_negative_files)
    overall_accuracy = total_correct / total_files if total_files > 0 else 0
    
    logger.info("üéØ –û–ë–©–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    logger.info(f"   –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {overall_accuracy:.2%}")
    logger.info(f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö: {pos_accuracy:.2%}")
    logger.info(f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö: {neg_accuracy:.2%}")
    logger.info(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ): {pos_confidence:.4f}")
    logger.info(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ): {neg_confidence:.4f}")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    logger.info("üìä –ê–ù–ê–õ–ò–ó –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø:")
    logger.info(f"   –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: –º–∏–Ω={min(pos_predictions):.4f}, –º–∞–∫—Å={max(pos_predictions):.4f}, —Å—Ä–µ–¥–Ω–µ–µ={np.mean(pos_predictions):.4f}")
    logger.info(f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: –º–∏–Ω={min(neg_predictions):.4f}, –º–∞–∫—Å={max(neg_predictions):.4f}, —Å—Ä–µ–¥–Ω–µ–µ={np.mean(neg_predictions):.4f}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
    if pos_confidence > 0.9 and neg_confidence < 0.1:
        logger.warning("‚ö†Ô∏è –í–û–ó–ú–û–ñ–ù–û–ï –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï: –°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
    elif pos_confidence < 0.5 or neg_confidence > 0.5:
        logger.warning("‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–´ –° –ú–û–î–ï–õ–¨–Æ: –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö")
    else:
        logger.info("‚úÖ –ú–û–î–ï–õ–¨ –†–ê–ë–û–¢–ê–ï–¢ –ö–û–†–†–ï–ö–¢–ù–û")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    logger.info("üìà –°–†–ê–í–ù–ï–ù–ò–ï –° –ü–†–ï–î–´–î–£–©–ò–ú–ò –†–ï–ó–£–õ–¨–¢–ê–¢–ê–ú–ò:")
    logger.info("   –ü—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (Librosa):")
    logger.info("     –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ: 100.00% —Ç–æ—á–Ω–æ—Å—Ç—å, 0.9864 —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
    logger.info("     –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ: 3.00% —Ç–æ—á–Ω–æ—Å—Ç—å, 0.7689 —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
    logger.info("   –¢–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (MicroFrontend):")
    logger.info(f"     –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ: {pos_accuracy:.2%} —Ç–æ—á–Ω–æ—Å—Ç—å, {pos_confidence:.4f} —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
    logger.info(f"     –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ: {neg_accuracy:.2%} —Ç–æ—á–Ω–æ—Å—Ç—å, {neg_confidence:.4f} —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")

if __name__ == "__main__":
    main()